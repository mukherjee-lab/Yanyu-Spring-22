{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSHROOMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../DATA/'\n",
    "FILE_NAME = 'mushrooms.csv'\n",
    "def load_data(data_path=DATA_PATH, file_name=FILE_NAME):\n",
    "    csv_path = os.path.join(data_path, file_name)\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data and Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edible:\t   4208 \n",
      "Poisonous: 3916\n"
     ]
    }
   ],
   "source": [
    "edible, poisonous = dataset['class'].value_counts()\n",
    "\n",
    "print(\"Edible:\\t  \", edible,\"\\nPoisonous:\", poisonous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Edible:    4208 \n",
      "1 - Poisonous: 3916\n"
     ]
    }
   ],
   "source": [
    "# Categorical to numerical\n",
    "labels = {'e': 0, 'p': 1}\n",
    "dataset['class'].replace(labels, inplace=True)\n",
    "\n",
    "edible, poisonous = dataset['class'].value_counts()\n",
    "print(\"0 - Edible:   \", edible,\"\\n1 - Poisonous:\", poisonous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN1 Stalk Root - Rooted (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (8124, 22) \n",
      "y: (8124,)\n"
     ]
    }
   ],
   "source": [
    "X, y =  dataset.drop('class', axis=1), dataset['class'].copy()\n",
    "\n",
    "print(\"X:\",X.shape,\"\\ny:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_white = pd.DataFrame()\n",
    "X_not_white = pd.DataFrame()\n",
    "y_white = pd.Series(dtype='float64')\n",
    "y_not_white = pd.Series(dtype='float64')\n",
    "for i in range(0,len(X)):\n",
    "    if X.loc[i,\"stalk-root\"] == \"r\":\n",
    "        X_white = X_white.append(X.iloc[i,:])\n",
    "        y_white = y_white.append(pd.Series(y.iloc[i]))\n",
    "    else:\n",
    "        X_not_white = X_not_white.append(X.iloc[i,:])\n",
    "        y_not_white = y_not_white.append(pd.Series(y.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_not_white, X_test_not_white, y_train_not_white, y_test_not_white = train_test_split(X_not_white, y_not_white, test_size=1-(6905/(8124-len(X_white))), random_state=37)\n",
    "\n",
    "# print(X_test_white)\n",
    "X_train_white = (X_train_not_white)\n",
    "# X_test_white = X_white.append(X_test_not_white)\n",
    "y_train_white = (y_train_not_white)\n",
    "# y_test_white = y_white.append(y_test_not_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_full1 = shuffle(X_train_white, random_state=37)\n",
    "X_test = shuffle(X, random_state=37).iloc[2000:4000]\n",
    "y_train_full1 = shuffle(y_train_white, random_state=37)\n",
    "y_test = shuffle(y, random_state=37).iloc[2000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test[:5])\n",
    "# print(y_test.loc[:,\"0\"])\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=37)\n",
    "\n",
    "# print(\"85% - X_train size:\", X_train_full.shape[0], \" y_train size:\", y_train_full.shape[0])\n",
    "# print(\"15% - X_test size: \", X_test.shape[0], \" y_test size: \", y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 6404 y_train 6404\n",
      "X_valid:  500 y_valid  500\n",
      "X_test:  2000 y_test  2000\n"
     ]
    }
   ],
   "source": [
    "X_valid1, X_train1 = X_train_full1[:500], X_train_full1[500:]\n",
    "y_valid1, y_train1 = y_train_full1[:500], y_train_full1[500:]\n",
    "\n",
    "print(\"X_train:\", X_train1.shape[0], \"y_train\", y_train1.shape[0])\n",
    "print(\"X_valid: \", X_valid1.shape[0], \"y_valid \", y_valid1.shape[0])\n",
    "print(\"X_test: \", X_test.shape[0], \"y_test \", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cat_attr_pipeline = Pipeline([\n",
    "                        ('encoder', OrdinalEncoder())\n",
    "                    ])\n",
    "\n",
    "cols = list(X)\n",
    "pipeline = ColumnTransformer([\n",
    "                ('cat_attr_pipeline', cat_attr_pipeline, cols)\n",
    "            ])\n",
    "\n",
    "\n",
    "X_train1 = pipeline.fit_transform(X_train1)\n",
    "X_valid1 = pipeline.fit_transform(X_valid1)\n",
    "X_test1  = pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential([\n",
    "    InputLayer(input_shape=(22,)),    # input  layer\n",
    "    Dense(45, activation='relu'),     # hidden layer\n",
    "    Dense(1,   activation='sigmoid')  # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 45)                1035      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 46        \n",
      "=================================================================\n",
      "Total params: 1,081\n",
      "Trainable params: 1,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint('../SavedModels/best_model.h5',\n",
    "                                save_best_only=True)\n",
    "\n",
    "early_stopping_cb = EarlyStopping(patience=3,\n",
    "                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6404 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "6404/6404 [==============================] - 1s 124us/sample - loss: 0.4640 - acc: 0.7900 - val_loss: 0.4018 - val_acc: 0.8480\n",
      "Epoch 2/100\n",
      "6404/6404 [==============================] - 0s 52us/sample - loss: 0.3173 - acc: 0.8841 - val_loss: 0.3203 - val_acc: 0.8720\n",
      "Epoch 3/100\n",
      "6404/6404 [==============================] - 0s 62us/sample - loss: 0.2729 - acc: 0.9044 - val_loss: 0.2991 - val_acc: 0.8920\n",
      "Epoch 4/100\n",
      "6404/6404 [==============================] - 0s 43us/sample - loss: 0.2474 - acc: 0.9122 - val_loss: 0.2637 - val_acc: 0.8840\n",
      "Epoch 5/100\n",
      "6404/6404 [==============================] - 0s 50us/sample - loss: 0.2251 - acc: 0.9190 - val_loss: 0.3855 - val_acc: 0.8360\n",
      "Epoch 6/100\n",
      "6404/6404 [==============================] - 0s 65us/sample - loss: 0.2121 - acc: 0.9249 - val_loss: 0.2222 - val_acc: 0.9100\n",
      "Epoch 7/100\n",
      "6404/6404 [==============================] - 0s 50us/sample - loss: 0.1960 - acc: 0.9305 - val_loss: 0.5633 - val_acc: 0.7160\n",
      "Epoch 8/100\n",
      "6404/6404 [==============================] - 0s 60us/sample - loss: 0.1870 - acc: 0.9344 - val_loss: 0.2001 - val_acc: 0.9200\n",
      "Epoch 9/100\n",
      "6404/6404 [==============================] - 0s 55us/sample - loss: 0.1750 - acc: 0.9374 - val_loss: 0.1914 - val_acc: 0.9200\n",
      "Epoch 10/100\n",
      "6404/6404 [==============================] - 0s 56us/sample - loss: 0.1645 - acc: 0.9418 - val_loss: 0.1775 - val_acc: 0.9520\n",
      "Epoch 11/100\n",
      "6404/6404 [==============================] - 0s 34us/sample - loss: 0.1590 - acc: 0.9433 - val_loss: 0.1817 - val_acc: 0.9180\n",
      "Epoch 12/100\n",
      "6404/6404 [==============================] - 0s 62us/sample - loss: 0.1478 - acc: 0.9475 - val_loss: 0.1625 - val_acc: 0.9440\n",
      "Epoch 13/100\n",
      "6404/6404 [==============================] - 0s 56us/sample - loss: 0.1396 - acc: 0.9522 - val_loss: 0.1639 - val_acc: 0.9580\n",
      "Epoch 14/100\n",
      "6404/6404 [==============================] - 0s 70us/sample - loss: 0.1337 - acc: 0.9527 - val_loss: 0.1477 - val_acc: 0.9580\n",
      "Epoch 15/100\n",
      "6404/6404 [==============================] - 0s 69us/sample - loss: 0.1258 - acc: 0.9553 - val_loss: 0.2095 - val_acc: 0.9080\n",
      "Epoch 16/100\n",
      "6404/6404 [==============================] - 0s 74us/sample - loss: 0.1229 - acc: 0.9561 - val_loss: 0.1478 - val_acc: 0.9560\n",
      "Epoch 17/100\n",
      "6404/6404 [==============================] - 1s 82us/sample - loss: 0.1154 - acc: 0.9575 - val_loss: 0.1996 - val_acc: 0.9140\n"
     ]
    }
   ],
   "source": [
    "train_model1 = model1.fit(X_train1, y_train1,\n",
    "                        epochs=100,\n",
    "                        validation_data=(X_valid1, y_valid1),\n",
    "                        callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 37us/sample - loss: 0.1439 - acc: 0.9430\n",
      "test loss, test acc: [0.1438773773908615, 0.943]\n"
     ]
    }
   ],
   "source": [
    "results1 = model1.evaluate(X_test1, y_test)\n",
    "print(\"test loss, test acc:\", results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new1 = X_test1[:5]\n",
    "y_prob1 = model1.predict(X_new1)\n",
    "# print(y_prob.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = (model1.predict(X_new1) > 0.5).astype(\"int32\")\n",
    "# print(y_pred)\n",
    "y_test_pred = (model1.predict(X_test1) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_pred  y_pred  y_actual\n",
      "0     0.979996       1         1\n",
      "1     0.895362       1         1\n",
      "2     0.866164       1         1\n",
      "3     0.734473       1         1\n",
      "4     0.958439       1         1\n",
      "...        ...     ...       ...\n",
      "1995  0.805070       1         1\n",
      "1996  0.997322       1         1\n",
      "1997  0.391174       0         1\n",
      "1998  0.007026       0         0\n",
      "1999  0.985243       1         1\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# X_new = X_test[:5]\n",
    "X_df1 = pd.DataFrame(model1.predict(X_test1))\n",
    "y_test_pred1 = pd.DataFrame(y_test_pred).reset_index(drop=True)\n",
    "X_df1 = pd.concat([X_df1, y_test_pred1], axis=1)\n",
    "y_test1 = y_test.reset_index(drop=True)\n",
    "X_df1 = pd.concat([X_df1, y_test1], axis=1)\n",
    "X_df1.columns = [\"X_pred\",\"y_pred\",\"y_actual\"]\n",
    "print(X_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        KL_div abs_distance correctness  y_pred\n",
      "0     0.098054     0.959992           1     1.0\n",
      "1     0.335157     0.790723           1     1.0\n",
      "2     0.393614     0.732329           1     1.0\n",
      "3     0.578759     0.468946           1     1.0\n",
      "4     0.172874     0.916878           1     1.0\n",
      "...        ...          ...         ...     ...\n",
      "1995  0.493294     0.610139           1     1.0\n",
      "1996  0.018534     0.994645           1     1.0\n",
      "1997  0.669271     0.217651           0     0.0\n",
      "1998  0.041836     0.985949           1     0.0\n",
      "1999  0.076863     0.970486           1     1.0\n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "table1 = pd.DataFrame(columns=[\"KL_div\",\"abs_distance\",\"correctness\"])\n",
    "for i in range(0,len(X_df1)):\n",
    "    # KL divergence\n",
    "    p = X_df1.loc[i,\"X_pred\"]\n",
    "    try:\n",
    "        kl = -(p*math.log(p) + (1-p)*math.log(1-p))\n",
    "    except:\n",
    "        kl = 0\n",
    "    table1.loc[i,\"KL_div\"] = kl\n",
    "    # absolute distance\n",
    "    abs_dist = 2*abs(0.5-p)\n",
    "    table1.loc[i,\"abs_distance\"] = abs_dist\n",
    "    # correctness\n",
    "    y_pred1 = X_df1.loc[i,\"y_pred\"]\n",
    "    y_act1 = X_df1.loc[i,\"y_actual\"]\n",
    "    if y_pred1 == y_act1:\n",
    "        table1.loc[i,\"correctness\"] = 1 # correct prediction\n",
    "    else:\n",
    "        table1.loc[i,\"correctness\"] = 0 # wrong prediction\n",
    "    table1.loc[i,\"y_pred\"] = y_pred1\n",
    "\n",
    "print(table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correctness  count     percent\n",
      "KL_div                                    \n",
      "(0.0, 0.1]          720    720  100.000000\n",
      "(0.1, 0.2]          516    518   99.613900\n",
      "(0.2, 0.3]          276    282   97.872340\n",
      "(0.3, 0.4]          147    154   95.454545\n",
      "(0.4, 0.5]          100    117   85.470085\n",
      "(0.5, 0.6]           54     81   66.666667\n",
      "(0.6, 0.7]           73    128   57.031250\n"
     ]
    }
   ],
   "source": [
    "table1[\"count\"] = 1\n",
    "correctness1 = table1[[\"correctness\",\"count\"]].groupby(pd.cut(table1[\"KL_div\"], np.arange(0, 0.8, 0.1))).apply(sum)\n",
    "correctness1[\"percent\"] = 100*(correctness1[\"correctness\"]/correctness1[\"count\"])\n",
    "print(correctness1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% correct')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = []\n",
    "for i in (correctness1.index):\n",
    "    index.append(str(i))\n",
    "plt.bar(index,correctness1[\"percent\"], width=0.7)\n",
    "for index,data in enumerate(correctness1[\"percent\"]):\n",
    "    plt.text(x=index , y =data+1 , s=f\"{round(data,2)}\" , fontdict=dict(fontsize=15),ha='center')\n",
    "plt.ylim(0,110)\n",
    "plt.xlabel(\"KL Divergence\")\n",
    "plt.ylabel(\"% correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% correct')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kl1 = table1[[\"correctness\",\"count\"]].groupby(pd.cut(table1[\"KL_div\"], np.arange(0, 0.80, 0.1))).apply(sum)\n",
    "kl1[\"percent\"] = (kl1[\"correctness\"]/kl1[\"count\"])\n",
    "kl1.dropna(inplace=True)\n",
    "plt.scatter(np.arange(0, 0.70, 0.1), kl1[\"percent\"])\n",
    "plt.xlabel(\"KL Divergence\")\n",
    "plt.ylabel(\"% correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_reg1 = np.arange(0, 0.70, 0.1).reshape((-1, 1))\n",
    "y_reg1 = kl1[\"percent\"]\n",
    "reg_model1 = LinearRegression().fit(x_reg1,y_reg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept(alpha): 1.082158593954519\n",
      "slope(theta): [-0.74001061]\n"
     ]
    }
   ],
   "source": [
    "print('intercept(alpha):', reg_model1.intercept_)\n",
    "print('slope(theta):', reg_model1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN2 Odor - Almond (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_green = pd.DataFrame()\n",
    "X_not_green = pd.DataFrame()\n",
    "y_green = pd.Series(dtype='float64')\n",
    "y_not_green = pd.Series(dtype='float64')\n",
    "for i in range(0,len(X)):\n",
    "    if X.loc[i,\"odor\"] == \"a\":\n",
    "        X_green = X_green.append(X.iloc[i,:])\n",
    "        y_green = y_green.append(pd.Series(y.iloc[i]))\n",
    "    else:\n",
    "        X_not_green = X_not_green.append(X.iloc[i,:])\n",
    "        y_not_green = y_not_green.append(pd.Series(y.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_green, X_train_green, y_test_green, y_train_green = train_test_split(X_green, y_green, test_size=1, random_state=37)\n",
    "X_train_not_green, X_test_not_green, y_train_not_green, y_test_not_green = train_test_split(X_not_green, y_not_green, test_size=1-(6905/(8124-len(X_green))), random_state=37)\n",
    "\n",
    "# print(X_test_green)\n",
    "X_train_green = (X_train_not_green)\n",
    "X_test_green = X_green.append(X_test_not_green)\n",
    "y_train_green = (y_train_not_green)\n",
    "y_test_green = y_green.append(y_test_not_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_full2 = shuffle(X_train_green, random_state=37)\n",
    "# X_test2 = shuffle(X_test_green, random_state=37)\n",
    "y_train_full2 = shuffle(y_train_green, random_state=37)\n",
    "# y_test2 = shuffle(y_test_green, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 6404 y_train 6404\n",
      "X_valid:  500 y_valid  500\n",
      "X_test:  2000 y_test  2000\n"
     ]
    }
   ],
   "source": [
    "X_valid2, X_train2 = X_train_full2[:500], X_train_full2[500:]\n",
    "y_valid2, y_train2 = y_train_full2[:500], y_train_full2[500:]\n",
    "\n",
    "print(\"X_train:\", X_train2.shape[0], \"y_train\", y_train2.shape[0])\n",
    "print(\"X_valid: \", X_valid2.shape[0], \"y_valid \", y_valid2.shape[0])\n",
    "print(\"X_test: \", X_test.shape[0], \"y_test \", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cat_attr_pipeline = Pipeline([\n",
    "                        ('encoder', OrdinalEncoder())\n",
    "                    ])\n",
    "\n",
    "cols = list(X)\n",
    "pipeline = ColumnTransformer([\n",
    "                ('cat_attr_pipeline', cat_attr_pipeline, cols)\n",
    "            ])\n",
    "\n",
    "\n",
    "X_train2 = pipeline.fit_transform(X_train2)\n",
    "X_valid2 = pipeline.fit_transform(X_valid2)\n",
    "X_test2  = pipeline.fit_transform(X_test)\n",
    "y_test2 = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_random_seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    InputLayer(input_shape=(22,)),    # input  layer\n",
    "    Dense(45, activation='relu'),     # hidden layer\n",
    "    Dense(1,   activation='sigmoid')  # output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 45)                1035      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 46        \n",
      "=================================================================\n",
      "Total params: 1,081\n",
      "Trainable params: 1,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint('../SavedModels/best_model.h5',\n",
    "                                save_best_only=True)\n",
    "\n",
    "early_stopping_cb = EarlyStopping(patience=3,\n",
    "                                  restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6404 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "6404/6404 [==============================] - 1s 184us/sample - loss: 0.4080 - acc: 0.8415 - val_loss: 0.3221 - val_acc: 0.8880\n",
      "Epoch 2/100\n",
      "6404/6404 [==============================] - 0s 51us/sample - loss: 0.2856 - acc: 0.9079 - val_loss: 0.2908 - val_acc: 0.8800\n",
      "Epoch 3/100\n",
      "6404/6404 [==============================] - 0s 45us/sample - loss: 0.2464 - acc: 0.9188 - val_loss: 0.2366 - val_acc: 0.9280\n",
      "Epoch 4/100\n",
      "6404/6404 [==============================] - 0s 59us/sample - loss: 0.2215 - acc: 0.9232 - val_loss: 0.2203 - val_acc: 0.9140\n",
      "Epoch 5/100\n",
      "6404/6404 [==============================] - ETA: 0s - loss: 0.2062 - acc: 0.925 - 0s 57us/sample - loss: 0.2049 - acc: 0.9265 - val_loss: 0.1967 - val_acc: 0.9400\n",
      "Epoch 6/100\n",
      "6404/6404 [==============================] - 0s 65us/sample - loss: 0.1899 - acc: 0.9333 - val_loss: 0.1874 - val_acc: 0.9440\n",
      "Epoch 7/100\n",
      "6404/6404 [==============================] - 0s 60us/sample - loss: 0.1780 - acc: 0.9343 - val_loss: 0.2027 - val_acc: 0.9400\n",
      "Epoch 8/100\n",
      "6404/6404 [==============================] - 0s 37us/sample - loss: 0.1677 - acc: 0.9382 - val_loss: 0.1652 - val_acc: 0.9440\n",
      "Epoch 9/100\n",
      "6404/6404 [==============================] - 0s 55us/sample - loss: 0.1588 - acc: 0.9385 - val_loss: 0.1650 - val_acc: 0.9380\n",
      "Epoch 10/100\n",
      "6404/6404 [==============================] - 0s 66us/sample - loss: 0.1509 - acc: 0.9422 - val_loss: 0.1597 - val_acc: 0.9480\n",
      "Epoch 11/100\n",
      "6404/6404 [==============================] - 1s 89us/sample - loss: 0.1433 - acc: 0.9449 - val_loss: 0.1913 - val_acc: 0.9180\n",
      "Epoch 12/100\n",
      "6404/6404 [==============================] - 1s 87us/sample - loss: 0.1351 - acc: 0.9491 - val_loss: 0.1469 - val_acc: 0.9460\n",
      "Epoch 13/100\n",
      "6404/6404 [==============================] - 0s 75us/sample - loss: 0.1266 - acc: 0.9530 - val_loss: 0.1257 - val_acc: 0.9600\n",
      "Epoch 14/100\n",
      "6404/6404 [==============================] - 0s 71us/sample - loss: 0.1214 - acc: 0.9571 - val_loss: 0.1195 - val_acc: 0.9580\n",
      "Epoch 15/100\n",
      "6404/6404 [==============================] - 0s 60us/sample - loss: 0.1153 - acc: 0.9613 - val_loss: 0.1182 - val_acc: 0.9560\n",
      "Epoch 16/100\n",
      "6404/6404 [==============================] - 0s 59us/sample - loss: 0.1091 - acc: 0.9647 - val_loss: 0.1308 - val_acc: 0.9500\n",
      "Epoch 17/100\n",
      "6404/6404 [==============================] - 0s 47us/sample - loss: 0.1050 - acc: 0.9653 - val_loss: 0.1025 - val_acc: 0.9740\n",
      "Epoch 18/100\n",
      "6404/6404 [==============================] - 0s 61us/sample - loss: 0.0993 - acc: 0.9700 - val_loss: 0.1015 - val_acc: 0.9820\n",
      "Epoch 19/100\n",
      "6404/6404 [==============================] - 0s 40us/sample - loss: 0.0941 - acc: 0.9736 - val_loss: 0.0934 - val_acc: 0.9700\n",
      "Epoch 20/100\n",
      "6404/6404 [==============================] - 0s 70us/sample - loss: 0.0901 - acc: 0.9767 - val_loss: 0.0868 - val_acc: 0.9840\n",
      "Epoch 21/100\n",
      "6404/6404 [==============================] - 0s 53us/sample - loss: 0.0859 - acc: 0.9781 - val_loss: 0.0832 - val_acc: 0.9860\n",
      "Epoch 22/100\n",
      "6404/6404 [==============================] - 0s 39us/sample - loss: 0.0824 - acc: 0.9799 - val_loss: 0.0836 - val_acc: 0.9700\n",
      "Epoch 23/100\n",
      "6404/6404 [==============================] - 0s 43us/sample - loss: 0.0791 - acc: 0.9817 - val_loss: 0.0793 - val_acc: 0.9780\n",
      "Epoch 24/100\n",
      "6404/6404 [==============================] - 0s 41us/sample - loss: 0.0769 - acc: 0.9817 - val_loss: 0.0720 - val_acc: 0.9840\n",
      "Epoch 25/100\n",
      "6404/6404 [==============================] - 0s 45us/sample - loss: 0.0739 - acc: 0.9820 - val_loss: 0.0720 - val_acc: 0.9820\n",
      "Epoch 26/100\n",
      "6404/6404 [==============================] - 0s 47us/sample - loss: 0.0718 - acc: 0.9833 - val_loss: 0.0681 - val_acc: 0.9860\n",
      "Epoch 27/100\n",
      "6404/6404 [==============================] - 0s 39us/sample - loss: 0.0691 - acc: 0.9844 - val_loss: 0.1207 - val_acc: 0.9620\n",
      "Epoch 28/100\n",
      "6404/6404 [==============================] - 0s 41us/sample - loss: 0.0675 - acc: 0.9847 - val_loss: 0.0647 - val_acc: 0.9860\n",
      "Epoch 29/100\n",
      "6404/6404 [==============================] - 0s 45us/sample - loss: 0.0654 - acc: 0.9853 - val_loss: 0.1814 - val_acc: 0.9160\n",
      "Epoch 30/100\n",
      "6404/6404 [==============================] - 0s 42us/sample - loss: 0.0638 - acc: 0.9852 - val_loss: 0.0571 - val_acc: 0.9860\n",
      "Epoch 31/100\n",
      "6404/6404 [==============================] - 0s 40us/sample - loss: 0.0603 - acc: 0.9872 - val_loss: 0.0551 - val_acc: 0.9860\n",
      "Epoch 32/100\n",
      "6404/6404 [==============================] - 0s 38us/sample - loss: 0.0590 - acc: 0.9867 - val_loss: 0.0571 - val_acc: 0.9840\n",
      "Epoch 33/100\n",
      "6404/6404 [==============================] - 0s 46us/sample - loss: 0.0572 - acc: 0.9875 - val_loss: 0.0552 - val_acc: 0.9880\n",
      "Epoch 34/100\n",
      "6404/6404 [==============================] - 0s 43us/sample - loss: 0.0553 - acc: 0.9886 - val_loss: 0.0510 - val_acc: 0.9860\n",
      "Epoch 35/100\n",
      "6404/6404 [==============================] - 0s 38us/sample - loss: 0.0541 - acc: 0.9881 - val_loss: 0.0539 - val_acc: 0.9920\n",
      "Epoch 36/100\n",
      "6404/6404 [==============================] - 0s 40us/sample - loss: 0.0530 - acc: 0.9875 - val_loss: 0.0503 - val_acc: 0.9900\n",
      "Epoch 37/100\n",
      "6404/6404 [==============================] - 0s 43us/sample - loss: 0.0520 - acc: 0.9886 - val_loss: 0.0505 - val_acc: 0.9920\n",
      "Epoch 38/100\n",
      "6404/6404 [==============================] - 0s 54us/sample - loss: 0.0498 - acc: 0.9881 - val_loss: 0.0460 - val_acc: 0.9860\n",
      "Epoch 39/100\n",
      "6404/6404 [==============================] - 0s 58us/sample - loss: 0.0495 - acc: 0.9899 - val_loss: 0.0446 - val_acc: 0.9860\n",
      "Epoch 40/100\n",
      "6404/6404 [==============================] - 0s 56us/sample - loss: 0.0480 - acc: 0.9895 - val_loss: 0.0456 - val_acc: 0.9920\n",
      "Epoch 41/100\n",
      "6404/6404 [==============================] - 0s 54us/sample - loss: 0.0472 - acc: 0.9883 - val_loss: 0.0428 - val_acc: 0.9860\n",
      "Epoch 42/100\n",
      "6404/6404 [==============================] - 0s 43us/sample - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0598 - val_acc: 0.9920\n",
      "Epoch 43/100\n",
      "6404/6404 [==============================] - 0s 60us/sample - loss: 0.0459 - acc: 0.9894 - val_loss: 0.0433 - val_acc: 0.9880\n",
      "Epoch 44/100\n",
      "6404/6404 [==============================] - 0s 61us/sample - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0392 - val_acc: 0.9860\n",
      "Epoch 45/100\n",
      "6404/6404 [==============================] - 0s 47us/sample - loss: 0.0430 - acc: 0.9902 - val_loss: 0.0381 - val_acc: 0.9880\n",
      "Epoch 46/100\n",
      "6404/6404 [==============================] - 0s 41us/sample - loss: 0.0426 - acc: 0.9897 - val_loss: 0.0379 - val_acc: 0.9920\n",
      "Epoch 47/100\n",
      "6404/6404 [==============================] - 0s 39us/sample - loss: 0.0419 - acc: 0.9903 - val_loss: 0.0383 - val_acc: 0.9920\n",
      "Epoch 48/100\n",
      "6404/6404 [==============================] - 0s 47us/sample - loss: 0.0416 - acc: 0.9903 - val_loss: 0.0380 - val_acc: 0.9920\n",
      "Epoch 49/100\n",
      "6404/6404 [==============================] - 0s 55us/sample - loss: 0.0400 - acc: 0.9905 - val_loss: 0.0408 - val_acc: 0.9920\n"
     ]
    }
   ],
   "source": [
    "train_model2 = model2.fit(X_train2, y_train2,\n",
    "                        epochs=100,\n",
    "                        validation_data=(X_valid2, y_valid2),\n",
    "                        callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 36us/sample - loss: 0.1863 - acc: 0.9330\n",
      "test loss, test acc: [0.18632307776808738, 0.933]\n"
     ]
    }
   ],
   "source": [
    "results2 = model2.evaluate(X_test2, y_test2)\n",
    "print(\"test loss, test acc:\", results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new2 = X_test2[1100:1110]\n",
    "y_prob2 = model2.predict(X_new2)\n",
    "# print(y_prob2.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = (model2.predict(X_new2) > 0.5).astype(\"int32\")\n",
    "# print(y_pred2)\n",
    "y_test_pred2 = (model2.predict(X_test2) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        X_pred  y_pred  y_actual\n",
      "0     0.999979       1         1\n",
      "1     0.932437       1         1\n",
      "2     0.784315       1         1\n",
      "3     0.901394       1         1\n",
      "4     0.922961       1         1\n",
      "...        ...     ...       ...\n",
      "1995  0.719968       1         1\n",
      "1996  0.998294       1         1\n",
      "1997  0.290893       0         1\n",
      "1998  0.001422       0         0\n",
      "1999  0.997806       1         1\n",
      "\n",
      "[2000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# X_new = X_test[:5]\n",
    "X_df2 = pd.DataFrame(model2.predict(X_test2))\n",
    "y_test_pred2 = pd.DataFrame(y_test_pred2).reset_index(drop=True)\n",
    "X_df2 = pd.concat([X_df2, y_test_pred2], axis=1)\n",
    "y_test2 = y_test2.reset_index(drop=True)\n",
    "X_df2 = pd.concat([X_df2, y_test2], axis=1)\n",
    "X_df2.columns = [\"X_pred\",\"y_pred\",\"y_actual\"]\n",
    "print(X_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        KL_div abs_distance y_pred correctness\n",
      "0     0.000249     0.999958      1           1\n",
      "1     0.247288     0.864875      1           1\n",
      "2     0.521392     0.568631      1           1\n",
      "3      0.32201     0.802787      1           1\n",
      "4     0.271477     0.845922      1           1\n",
      "...        ...          ...    ...         ...\n",
      "1995  0.592984     0.439935      1           1\n",
      "1996  0.012577     0.996588      1           1\n",
      "1997  0.602949     0.418214      0           0\n",
      "1998  0.010744     0.997156      0           1\n",
      "1999  0.015624     0.995612      1           1\n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "table2 = pd.DataFrame(columns=[\"KL_div\",\"abs_distance\",\"y_pred\",\"correctness\"])\n",
    "for i in range(0,len(X_df2)):\n",
    "    # KL divergence\n",
    "    p = X_df2.loc[i,\"X_pred\"]\n",
    "    kl = -(p*math.log(p) + (1-p)*math.log(1-p))\n",
    "    table2.loc[i,\"KL_div\"] = kl\n",
    "    # absolute distance\n",
    "    abs_dist = 2*abs(0.5-p)\n",
    "    table2.loc[i,\"abs_distance\"] = abs_dist\n",
    "    # correctness\n",
    "    y_pred = X_df2.loc[i,\"y_pred\"]\n",
    "    y_act = X_df2.loc[i,\"y_actual\"]\n",
    "    if y_pred == y_act:\n",
    "        table2.loc[i,\"correctness\"] = 1 # correct prediction\n",
    "    else:\n",
    "        table2.loc[i,\"correctness\"] = 0 # wrong prediction\n",
    "    table2.loc[i,\"y_pred\"] = y_pred\n",
    "\n",
    "print(table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            correctness  count    percent\n",
      "KL_div                                   \n",
      "(0.0, 0.1]         1164   1168  99.657534\n",
      "(0.1, 0.2]          243    260  93.461538\n",
      "(0.2, 0.3]          139    161  86.335404\n",
      "(0.3, 0.4]          101    117  86.324786\n",
      "(0.4, 0.5]           67     94  71.276596\n",
      "(0.5, 0.6]           75     87  86.206897\n",
      "(0.6, 0.7]           77    113  68.141593\n"
     ]
    }
   ],
   "source": [
    "table2[\"count\"] = 1\n",
    "correctness2 = table2[[\"correctness\",\"count\"]].groupby(pd.cut(table2[\"KL_div\"], np.arange(0, 0.8, 0.1))).apply(sum)\n",
    "correctness2[\"percent\"] = 100*(correctness2[\"correctness\"]/correctness2[\"count\"])\n",
    "print(correctness2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% correct')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtiElEQVR4nO3deXgUVdr38e9NQtghIaAsjoCs6qAiQRyEGSWIICjgCo+jIDKKjyv4Cuo4biMji8vrwKgv4oCoQ1BcANlEwHFcYAgKiCggioqyqUEQkfV+/+hKmUCWJums/D7X1Vd3nTp96q5Kp++uOlWnzN0REREBqFDSAYiISOmhpCAiIiElBRERCSkpiIhISElBRERC8SUdQGHUqVPHGzduXNJhiIiUKcuWLfvO3evmNK9MJ4XGjRuTnp5e0mGIiJQpZvZlbvN0+EhEREJKCiIiElJSEBGRkJKCiIiElBRERCSkpCAiIqGjKim89tprnHLKKVSqVIkmTZrw6KOPHlZn+/btDBw4kNq1a1O9enW6d+/OZ599FlX733//Pddddx316tWjSpUqtGrVismTJx9W75VXXqFdu3ZUqVKF5ORkunXrxq5duwq9fiIihVWmr1M4Eu+++y4XXXQRAwcO5OGHH2bJkiUMHz6cChUqcOutt4b1Lr/8clatWsXjjz9OrVq1ePDBB0lNTeWjjz6iZs2auba/Y8cOfv/731O9enXGjh1LnTp1WL16NXv37s1Wb8KECdx4440MGzaMMWPGkJGRwcKFC9m/f39RrbqISPTcvcw+2rZt69Hq2rWrd+rUKVvZkCFDPCkpyffs2ePu7u+9954DvmDBgrDO5s2bvUqVKj5mzJg82x8+fLg3bdrUf/7551zrbNu2zatXr+7jx4+POm4RkVgD0j2X79Wj5vDR8uXL6dKlS7ayrl27kpGRwfvvvx/WiY+P5w9/+ENY59hjj+WUU05h1qxZebY/ceJErrnmGqpUqZJrnRdffBGA/v37F3Q1RESK1FGTFH755RcSEhKylVWqVAmATz75JKwTHx9PXFzcYfUy6+Tkiy++YOvWrSQmJnL++eeTkJBA3bp1GTp0aLbDR0uWLKFly5Y888wzHHfccVSsWJH27dvz3nvvxWo1RUQK5ahJCs2aNWPp0qXZyv773/8C8MMPP4R1fvnlFz766KOwzu7du1m1alVYJyebN28GYNiwYTRs2JC5c+dy11138eSTT3L33Xdnq7dmzRoefPBBRo0axcyZM6lWrRrdunVjy5YtMVtXEZECy+24Ull4HEmfwvjx4z0uLs7Hjx/vP/zwg8+dO9fr1q3rgI8cOdLd3ffs2eNNmjTx3/3ud/7pp5/6t99+61dddZXHxcV55cqVc237nXfeccDbt2+frfz+++/3SpUq+a5du9zdvUuXLg74nDlzwjo//vijJyYm+t133x31uoiIFAbqU4CBAwcyePBgrr/+emrXrs1FF13EPffcA0T6DQASEhJIS0tjy5YttGrVigYNGvD5559z1VVXhXVyUrt2bQDOOeecbOWdO3dmz549rF+/Plu9s88+O6xTs2ZN2rZty+rVq2O2riIiBXXUJIW4uDjGjRvHtm3bWLlyJVu2bOHMM88ECJ8BzjjjDD777DM+/fRTPvvsM/7zn/+wdevWbHUO1bRp08P6KyCyFwZQoUJkM5944omYWVietV5mHRGRklRk30Rm9k8z22pmq7KU1Taz+Wa2LnhOyjLvTjP7zMzWmNl5RRVXUlISrVu3pnr16jzxxBN06NCBVq1aHRo7LVu2pGnTpqxbt44333yTa665Jtc2ExISOPfcc1m4cGG28gULFlC1alWaNWsGQM+ePXF3Fi1aFNb58ccfWbZsGaeeemoM11JEpIByO65U2Afwe+B0YFWWstHAHcHrO4BRweuTgBVAJaAJsB6Iy28ZR9Kn8P777/uYMWN8/vz5/vLLL/sll1ziNWrU8BUrVmSr98ADD/iLL77oCxcu9Mcff9zr1Knj/fv3z1bn2Wef9bi4ON+wYUNYtmTJEq9YsaIPGDDA582b52PGjPFKlSr5gw8+mO29vXr18nr16vmkSZP89ddf99///vdep04d/+GHH6JeFxGRwiCPPoUi7QgGGh+SFNYA9YPX9YE1wes7gTuz1JsH/C6/9o8kKaSnp3tKSopXq1bNa9So4eeff76vXLnysHq33HKLN2jQwBMSErxp06Y+cuRI37dvX7Y6EydOdMC/+OKLbOVz5871Nm3aeEJCgh933HH+wAMP+IEDB7LV2blzpw8ePNhr167tlStX9tTU1BzjEBEpKqUpKWw/ZH5G8DwO+GOW8meAS3Jp81ogHUg//vjji2iTlR6vvvqqt27d2hMSErxx48b+yCOPZJu/Z88ev/TSS71JkyZeuXJlr1Onjnfr1s3T09OPeDmA55ZoX375ZU9JSfHKlSt77dq1/bzzzvOffvqpwOslIiUnr6RQWsY+shzKPIcy3H08MB4gJSUlxzrRanxH3lcpF6UNI3vkWyea8ZoOHDiAmXHnnXfStGlTduzYwWOPPUbnzp358MMPOeGEE/Jdzi+//MLQoUNzPcNK4zWJHD2KOylsMbP67r7JzOoDW4PyjcBvstQ7Dvi2mGMrdR544AE6duzIhAkTgF+H5XjggQf43//9XxISEqhSpQpTp07N9r4uXbqQnJzMa6+9xtChQ/NdzpgxY2jYsCFNmzZl1apV2eZ99913DBkyhLFjx/KnP/0pLO/Tp08M1lBESpviPg9yBpA58E9/YHqW8r5mVsnMmgDNgf8Wc2ylTjTjNeWkWrVqVK5c+bARWnPy1VdfMXr0aB5//PEc52u8JpGjS1GekjoFeB9oaWYbzewaYCRwrpmtA84NpnH3j4EXgdXAXOAGdz9QVLGVFdGM15TJ3dm/fz+bN29m2LBhxMXF0a9fv3yXcdttt3HZZZdx+umn5zhf4zWJHF2K7PCRu+f2jZSaS/0RwIiiiqcsima8pkyjRo3izjvvBKBu3brMnj2bRo0a5dn+okWLmDdvHmvXrs21TtbxmkaPHk1ycjKjR4+mW7durFu3Ls8rvUWk7NFltKXY4MGDmT59Ok8//TQZGRnMmzePRx55BOCwkVwHDBjA0qVLmTFjBm3btqVnz555Dp2xf/9+br75Zu6++27q1auXa72DBw/y008/8cwzz3DFFVfQrVs3XnvttfAKcREpX5QUSrFoxmvKVK9ePVJSUrjggguYOXMmycnJjBw5Mte2n376abZv307//v3Zvn0727dvZ+/evRw4cIDt27ezb98+QOM1iRxtlBRKsWjHazpUfHw8rVu35vPPP8+1zpo1a9i4cSP16tUjKSmJpKQkpkyZwvLly0lKSgrPaNJ4TSJHF/1XlwHRjNeU1S+//MIHH3xAkyZNcq1z4403smjRomyP8847jxYtWrBo0SLOPfdcQOM1iRxtSsvFa5KDxYsX884773DaaaexY8cOpkyZwrx583jnnXfCOlOmTGHOnDl069aNBg0asGnTJp544gk2bdqU7RqFyZMnM3DgQNavX0+jRo1o1qxZOFBfpkmTJvHdd99lO1SUkpJCr169uOaaaxg5ciR16tRh9OjRVKxYkRtuuKHIt4GIFC8lhVKsYsWKTJ06lfvuu48KFSrQqVMn3n33XVq3bh3WadmyJc8//zxDhw4lIyOD+vXr0759e9LT0zn55JPDegcPHuTAgQOHHQaKxvPPP8/tt9/O0KFD+fnnnznrrLNYuHAhSUlJ+b9ZRMoUK8iXRGmRkpLi6enpBX5/aR/mQkSkKJjZMndPyWme9hTKmJJMZKBkJlLeqaNZikRaWhqnn3461atXp2HDhlx11VV8++3hw1l99NFH9OzZk1q1alGjRg3OOOMMli1blmfb9957L61bt6ZmzZrUqFGDlJSUw8Z/yurgwYO0bdsWM+P1118vtTEvXbqUq6++mmbNmlG1alVatmzJ/fffzy+//JJn22VRUW3rAwcOMGrUKDp16kRycjLJycl07dr1sItA9+7dy+23306nTp2oUqUKZjmNyXl0UlKQmJsxYwb9+vWjQ4cOTJ8+nVGjRvH222/Ts2dPDh48GNZbvnw5HTp0IDExkalTp/LSSy9xwQUXsHv37jzb37FjBwMGDGDq1Km8/PLLnH766fTt25dp06blWH/ChAl88803pT7mqVOnsn79eoYPH87s2bO54YYbePTRR7niiivybLusKcptvXv3bkaOHEm7du147rnneP7556lYsSIdO3bMlkx+/vlnJkyYQNWqVenQoUORrm9Zoz6FElLQwzBl4fBR3759WbduXbZ/whkzZtCrVy9Wr17NiSeeCESutTjhhBP417/+Vei4zjrrLJKTk5kxY0a28oyMDFq0aMHIkSMZNGgQM2fOpGfPnqUy5m3btlG3bt1sdcaPH891113Hhg0b8h22pKwoym194MABduzYke0kiL1799KiRQvOOeccJk6cGJa7O2bGuHHjuOmmmwp0EkZZlVefgvYUJOb27dtHrVq1spUlJiYChP94q1evZsmSJdx0000xWWZycnKOo8L+5S9/4ayzziI1Nccht0pVzIcmBIA2bdoAsHXr1sPmlVVFua3j4uIOOysuISGBk08++bBtqENGOVNSkJgbOHAg//nPf5g8eTI7duxg7dq13H333ZxzzjmcdNJJQGT0VYj8kj/11FOJj4+nadOmPPPMM1EvZ//+/Wzfvp0XXniBN954g8GDB2ebv3LlSiZOnMjDDz9cZmI+1HvvvUeFChVo2bJl1Mso7YprW2fas2cPy5YtC9uWvCkpSMz16NGDSZMmce2111KrVi1atmzJgQMHeOWVV8I6mzdvBuCqq67iiiuuYP78+XTr1o1BgwYxe/bsfJexePFiKlasSFJSEgMGDODxxx+nd+/e2ercdNNN3HDDDYddpFeaY85q8+bNjBgxgiuvvJKaNWvm235ZURzbOqsRI0aQkZHBoEGDYroe5ZVOSZWYW7RoEYMHD+aWW26he/fubNmyhfvuu48+ffrw5ptvEhcXF3YoDho0iGHDhgFwzjnn8Mknn/DQQw9x/vnn57mM1q1bs3TpUrZv386sWbO48cYbqVmzZngPibS0NNasWcPMmTPLTMxZ7d27l8suu4zq1avz2GOPRbUOZUVxbOtMs2bNYsSIETzyyCPlam+rKCkpSMzddtttXHjhhYwaNSosO+2002jVqhXTp0/noosuCkdfPeecc7K9t3PnzlF9CVarVo2UlEg/WZcuXfjxxx8ZPnw4/fr1Y9++fdx+++0MHz6cgwcPsn37dnbs2AHArl272LlzJzVq1ChVMWfl7lx11VV8/PHHvPvuu+XuyvHi2NYQOcX38ssv57rrrgvvaS750+EjiblPP/2U0047LVtZy5YtqVKlCuvXrwcIzzA5VEFHXz399NP5+uuv2bdvH7t27WLjxo0MHTo0HAE2c/C+vn37hp23pSnmrIYMGcL06dOZPn16ngMfllXFsa3Xrl1Ljx49SE1NZezYsYWO+WiipCAx16hRIz744INsZZ988gm7d++mcePGAHTo0IGkpCQWLFiQrd6CBQsKNPrqu+++G94utHr16oeNADtlyhQA/va3v/HCCy+UupgzPfTQQ4wdO5bnn3+ejh07HnGbZUFRb+tNmzZx3nnn0bRpU6ZMmXLYDakkbzp8JDE3ePBghgwZQoMGDcJjxg888ACNGzcOjwUnJCRwzz33MGzYMBITE2nXrh0vv/wyb7/9Nv/+97/Dtg4d3fXLL7/k6quv5n/+53844YQT+Omnn3j11VdJS0vjySefBCL3k8g60ivAhg0bgMhx/fbt25e6mAH+9a9/cddddzFgwAAaNmzI4sWLw3lNmzbN8ZTVsqgot/Xu3bvp3r07GRkZjBs3jpUrV4Z1K1WqlG0vcc6cOezatYvly5cDhBcStmvXrtxcE1IQSgoSczfffDMJCQk8+eSTPPXUUyQmJtKxY0ceeughqlWrFta79dZbOXjwIGPHjuW+++6jZcuWTJs2jU6dOoV1Dh3dNTExkQYNGvDggw+yefNmEhMTOemkk5g1a1bUnY+lNeY33ngDiAxhPmnSpGzxTZw4kQEDBhR4/UqTotzWW7ZsYcWKFQCHXaTYqFGj8McBwPXXX8+XX34ZTl966aVA+drWBaErmktIeb6iWURKN42SKiWqrCayshp3WVQWf6CVV+poFhGRkJKCiIiElBRERCSkpCAiIiElBRERCSkpiIhISElBRERCSgoiIhJSUhARkVCJJAUzG2JmH5vZKjObYmaVzay2mc03s3XBc/kaRF5EpAwo9qRgZg2Bm4EUd/8tEAf0Be4AFrh7c2BBMC0iIsWopA4fxQNVzCweqAp8C/QCng3mPwv0LpnQRESOXsWeFNz9G+Bh4CtgE/Cju78BHOvum4I6m4Bjcnq/mV1rZulmlr5t27biCltE5KhQEoePkojsFTQBGgDVzOyP0b7f3ce7e4q7p5SXm46IiJQWJXH4qAvwhbtvc/d9wCtAB2CLmdUHCJ63lkBsIiJHtZJICl8BZ5pZVTMzIBX4BJgB9A/q9Aeml0BsIiJHtZLoU1gCTAM+AD4KYhgPjATONbN1wLnBtIjk4eyzz8bMcny8//77ADzxxBP06NGD5ORkzIy33nor33YPHDjAqFGj6NSpE8nJySQnJ9O1a1eWLl16WN309HS6du1KcnIytWvXpkuXLixZsiTWqyrFpETOPnL3e929lbv/1t2vdPc97v69u6e6e/Pg+YeSiE2kLHniiSd4//33sz3OPfdc6tSpQ7t27YDIze1/+OEHzjvvvKjb3b17NyNHjqRdu3Y899xzPP/881SsWJGOHTuybNmysN7XX39Nly5d2L9/P5MnT+a5555j//79dO3aNdv9j6Xs0O04Rcqwk046Kdv03r17SU9P5/LLLyc+PvLv/d5771GhQgVWrVrFlClTomq3SpUqfP755yQl/XoNaWpqKi1atGDcuHFMnDgRgFmzZrFz505eeeUVEhMTAejQoQN16tRh9uzZXH/99TFYSylOGuZCpByZO3cuGRkZ9OvXLyyrUOHI/83j4uKyJQSAhIQETj75ZLZu/fUckH379hEfH0/16tXDsurVqxMfH4+7F2ANpKQpKYiUI2lpaTRs2JBOnTrFvO09e/awbNmybHsnF198MVWrVuW2225j69atbN26lSFDhpCUlMSll14a8xik6CkpiJQTP//8MzNnzuTyyy8ncmJfbI0YMYKMjAwGDRoUljVo0IBFixbx8ssvc+yxx3LsscfyyiuvMG/ePHQdUdmkpCBSTsycOZOffvop26GjWJk1axYjRoxg1KhRtGzZMizftGkTl1xyCW3btmXOnDnMmTOHtm3b0qNHD7766quYx1HS9u/fz8iRI2nevDmVKlXiuOOOY8iQIdnqbNq0iauvvpqGDRtSvXp12rRpwwsvvJBv2/Pnz6dfv340btwYM+O+++7Ls/7Bgwdp27YtZsbrr79emNXKRh3NIuVEWloazZo1IyUlJabtLl26lMsvv5zrrruOW2+9Ndu8MWPGsH//fqZNm0bFihUB6Ny5M82bN+fhhx/m73//e0xjKWlXX301CxYs4N5776VVq1Z8/fXXrF69Opx/8OBBLrzwQr7//ntGjx5NvXr1mDZtGn/84x+pWrUqffr0ybXtuXPnsnLlSlJTU0lLS8s3lgkTJvDNN9/EZL2yUlIQKQd+/PFH5syZw7Bhw2La7tq1a+nRowepqamMHTv2sPmffvopJ598cpgQ4NcO6fXr18c0lpI2d+5c0tLSWLFixWFnfWVau3Yt6enpzJgxgwsuuACInLW1ZMkS0tLS8kwKY8aM4ZFHHgFg+vS8r93NyMjgz3/+MyNHjsx2OC8WdPhIpBx49dVX2bNnT0wPHW3atInzzjuPpk2bMmXKFOLi4g6r06hRI1atWsXevXvDsj179rBq1SoaN24cs1hKg3/+85907tw514QAkbOxAGrVqpWtPDExMd+zsY7kLLG//OUvnHXWWaSmpkb9nmgpKYiUA2lpaZx66qmceOKJh81LT09n2rRpzJ8/H4B///vfTJs2jfT09LDO5MmTiY+PDy842717N927dycjI4O7776blStXsnjxYhYvXsyHH34Yvm/QoEF8++239OnTh1mzZvH666/Tu3dvNm3axLXXXlvEa128lixZQosWLbjxxhupWbMmVatW5aKLLuLbb78N6/z2t7+lffv23HPPPaxbt44dO3YwadIk3n33XQYPHhyTOFauXMnEiRN5+OGHY9LeoXT4SKSM++6771iwYAF//etfc5w/btw4nn322XA6swOzf//+TJo0CYgcCz9w4ED4a3bLli2sWLECgJ49e2Zrr1GjRmzYsAGAtm3bMnfuXO6//36uvPJKAFq3bs38+fM59dRTY7WKpcLmzZuZNGkSp556KmlpaezcuZNhw4bRp08fFi9eHA4vMmfOHHr16kWLFi0AqFixIhMnTqRz584xieOmm27ihhtuoFmzZuHfIZaUFETKuDp16oSHLXIyadKk8Ms/NwMGDGDAgAHhdOPGjaO++Cw1NbVIDmOUNu6OuzN9+nSSk5MBqF+/Pn/4wx9YuHAhqampHDx4kCuvvJLvv/+eqVOncswxxzB79myuueYakpOT6datW6FiSEtLY82aNcycOTMWq5QjJQWRcqTxHbNKdPkbRvYo0eUXpaSkJE444YQwIQB07NiRhIQEVq9eTWpqKq+//jqzZs1i7dq1NG/eHIgMWvj1118zbNiwQiWFffv2cfvttzN8+HAOHjzI9u3b2bFjBwC7du1i586d1KhRo3ArifoURESiklN/DUT2IDI7iT/99FOqVq0aJoRMbdq0KfTZWLt27WLjxo0MHTqUpKQkkpKSwkN0ffv2pU2bNoVqP5P2FEREotCzZ0/uvfdevvvuO+rUqQPA22+/zb59+8Iv50aNGvHzzz+zZs2abBf5LVu2rNBnY1WvXp1FixZlK9u8eTP9+vXjb3/7W8z6LJQURESicO211/L3v/+dCy64gLvuuoudO3cyfPhwunTpQseOHQE4//zzOf744+nduzf33HMPdevWZdasWbz44ov84x//CNuaPHkyAwcOZP369TRq1AiAL7/8Mrxfxd69e1m9ejXTpk2jWrVqdO/enfj4eM4+++xsMWV2NLdu3Zr27dvHZD2VFEREolCzZk0WLlzIzTffTN++fUlISKBXr1489thjYZ0aNWqwYMEC7rzzTm677TZ27NhB06ZNeeqpp7Kdonvo2V4AixYt4uqrrw6nX3rpJV566aVsZ3sVByUFEZEoNWvWjNmzZ+db56WXXsqzzqFne+VWlp8jOUssWkoKIiIFUF7P9NLZRyIiElJSEBGRkJKCiIiE8k0KZtYkmjIRESn7otlTeDmHsmmxDkREREpermcfmVkr4GSglpldlGVWTaByUQcmIiLFL69TUlsCPYFE4IIs5TuBPxVhTCIiUkJyTQruPh2Ybma/c/f3izEmEREpIdH0KQw2s8TMCTNLMrN/Fl1IIiJSUqJJCqe4+/bMCXfPAGIzRquIiJQq0SSFCmaWlDlhZrXR8BgiIuVSNF/ujwDvmdk0wIHLgBFFGpWIiJSIfPcU3H0ycDGwBdgGXOTuzxVmoWaWaGbTzOxTM/vEzH5nZrXNbL6ZrQuek/JvSUREYinaYS5qA7vcfSywLQZXND8OzHX3VsCpwCfAHcACd28OLAimRUSkGEUzzMW9wHDgzqCoIvB8QRdoZjWB3wPPALj73qAjuxfwbFDtWaB3QZchIiIFE82eQh/gQmAXgLt/C9QoxDJPIHIYaqKZfWhmE8ysGnCsu28KlrEJOCanN5vZtWaWbmbp27ZtK0QYIiJyqGiSwl6P3NrHAYIv8MKIB04HnnT3NkSSTdSHitx9vLunuHtK3bp1CxmKiIhkFU1SeNHM/h+QaGZ/At4Eni7EMjcCG919STA9jUiS2GJm9QGC562FWIaIiBRAnqekmpkBU4FWwA4i4yHd4+7zC7pAd99sZl+bWUt3XwOkAquDR39gZPA8vaDLEBGRgskzKbi7m9lr7t4WKHAiyMFNwAtmlgB8DlxNZK/lRTO7BvgKuDSGyxMRkShEc/HaYjNr5+5LY7VQd18OpOQwKzVWyxARkSMXTVI4B7jOzL4k0ilsRHYiTinSyEREpNhF06cwGPiyeMIREZGSFE2fwmNBn4KIiJRz0ZySutjM2hV5JCIiUuKi7VMYbGYbUJ+CiEi5Fk1S6F7kUYiISKkQzdDZXwKJwAXBIzEoExGRciaaUVJvAV4gMkDdMcDzZnZTUQcmIiLFL5rDR9cA7d19F4CZjQLeB8YWZWAiIlL8ojn7yIADWaYPBGUiIlLORLOnMBFYYmavBtO9CW6QIyIi5Uu+ScHdHzWzt4CORPYQrnb3D4s6MBERKX75JgUzOxP42N0/CKZrmFn7LPdDEBGRciKaPoUngZ+yTO8KykREpJyJqqM5uB0nAO5+kOj6IkREpIyJJil8bmY3m1nF4HELkRvjiIhIORNNUhgMdAC+IXJ/5fbAtUUZlIiIlIxozj7aCvQthlhERKSERbOnICIiRwklBRERCSkpiIhIKOqkYGZnmtlCM3vXzHoXYUwiIlJCcu1oNrN67r45S9FQ4EIiQ128B7xWtKGJiEhxy+vso6fMbBkwxt1/AbYD/wMcBHYUQ2wiIlLMcj185O69geXA62Z2JXArkYRQlchIqSIiUs7k2afg7jOB84jcjvMVYI27/93dtxVDbCIiUsxyTQpmdqGZvQMsBFYRuYCtj5lNMbOmxRWgiIgUn7z6FB4EfgdUAWa7+xnAUDNrDoxAVzmLiJQ7eSWFH4l88VcBtmYWuvs6lBBERMqlvPoU+hDpVN5P5KwjEREp53LdU3D374CxxRiLiIiUsBIb5sLM4szsQzN7PZiubWbzzWxd8JxUUrGJiBytSnLso1uAT7JM3wEscPfmwIJgWkREilGJJAUzOw7oAUzIUtwLeDZ4/Sy6QE5EpNiV1J7C/wWGEblCOtOx7r4JIHg+Jqc3mtm1ZpZuZunbtukaOhGRWCr2pGBmPYGt7r6sIO939/HunuLuKXXr1o1xdCIiR7d8b8dZBM4CLjSz84HKQE0zex7YYmb13X2TmdUny7URIiJSPIp9T8Hd73T349y9MZGL4Ba6+x+BGUD/oFp/YHpxxyYicrQrTXdeGwmca2brgHODaRERKUYlcfgo5O5vAW8Fr78HUksyHhGRo11p2lMQEZESpqQgIiIhJQUREQkpKYiISEhJQUREQkoKIiISUlIQEZGQkoKIiISUFEREJKSkICIiISUFEREJKSmIiEhISUFEREJKCiIiElJSEBGRkJKCiIiElBRERCSkpCAiIiElBRERCSkpiIhISElBRERCSgoiIhJSUhARkZCSgoiIhJQUREQkpKQgIiIhJQUREQkpKYiISEhJQUREQkoKIiISKvakYGa/MbNFZvaJmX1sZrcE5bXNbL6ZrQuek4o7NhGRo11J7CnsB25z9xOBM4EbzOwk4A5ggbs3BxYE0yIiUoyKPSm4+yZ3/yB4vRP4BGgI9AKeDao9C/Qu7thERI52JdqnYGaNgTbAEuBYd98EkcQBHJPLe641s3QzS9+2bVuxxSoicjQosaRgZtWBl4Fb3X1HtO9z9/HunuLuKXXr1i26AEVEjkIlkhTMrCKRhPCCu78SFG8xs/rB/PrA1pKITUTkaFYSZx8Z8Azwibs/mmXWDKB/8Lo/ML24YxMROdrFl8AyzwKuBD4ys+VB2V3ASOBFM7sG+Aq4tARiExE5qhV7UnD3dwDLZXZqccYiIiLZ6YpmEREJKSmIiEhISUFEREJKCiIiElJSEBGRkJKCiIiElBRERCSkpCAiIiElBRERCSkpiIhISElBRERCSgoiIhJSUhARkZCSgoiIhJQUREQkpKQgIiIhJQUREQkpKYiISEhJQUREQkoKIiISUlIQEZGQkoKIiISUFEREJKSkICIiISUFEREJKSmIiEhISUFEREJKCiIiElJSEBGRkJKCiIiElBRERCRU6pKCmXUzszVm9pmZ3VHS8YiIHE1KVVIwszjgH0B34CSgn5mdVLJRiYgcPUpVUgDOAD5z98/dfS+QBvQq4ZhERI4a5u4lHUPIzC4Burn7oGD6SqC9u9+Ypc61wLXBZEtgTbEHGlEH+K6Ell0YZTHushgzlM24y2LMUDbjLsmYG7l73ZxmxBd3JPmwHMqyZS13Hw+ML55wcmdm6e6eUtJxHKmyGHdZjBnKZtxlMWYom3GX1phL2+GjjcBvskwfB3xbQrGIiBx1SltSWAo0N7MmZpYA9AVmlHBMIiJHjVJ1+Mjd95vZjcA8IA74p7t/XMJh5abED2EVUFmMuyzGDGUz7rIYM5TNuEtlzKWqo1lEREpWaTt8JCIiJUhJQUREQkoKIiISKvdJwcyqmNm/gyE0MLP+ZrYuePTP5T2VzGxqMP7SEjNrHMVy2prZR8F7/m5mh11zYWbJZrbIzH4ys3GHzMssTylE3L83sw/MbH9wIWC+ooz7XDNbFtRbZmadc4q7gDEPNbPVZrbSzBaYWaMYxXyGmS0PHivMrE9OMQfTBYl7cBDDcjN7J5rhWKKJO0vd44MY/09OcRck5iztXGJmnrn+hY3ZzBqb2e4s2/upnGIOpguyrQeY2bYs7Q+KRdxBvVPM7H0z+zioX/nQuAu6rc3ssuCz/bGZ/SsWMZvZFVm2w3IzO2hmpx0ac37LypO7l+sHcANwS/C6NvB58JwUvE7K4T3/CzwVvO4LTI1iOf8FfkfkArw5QPcc6lQDOgKDgXE5zH8LSClE3I2BU4DJwCVRbp9o4m4DNAhe/xb4Jqe4CxjzOUDV4PX1MdzWVYH44HV9YGvmdIy2dc0sry8E5sYi7ix1XwZeAv5PrLZ1ULcG8DawOHP9Y7CtGwOr8mijsNt6ADn8v8Qg7nhgJXBqMJ0MxMXoc90c+DBzHnBMLD8fQf3WwOe5beuCPsr9ngJwBTA9eH0eMN/df3D3DGA+0C2H9/QCng1eTwNS8/lVV5/Il8T7HvnLTAZ6H1rP3Xe5+zvAL0URt7tvcPeVwMEo2j+SuD9098yLCD8GKptZpRjFvMjdfw4mFxO5YDEWMf/s7vuDycoccmV8DOLekWWyWj7tRx13ULc3kS+bvE7HLsjnGuCvwGii+AweScxHoKBxR+0I4u4KrHT3FQDu/r27H4hRzH8C/hHUwd23xijmrPoBU/Kpc8TKdVKwyAVwJ7j7hqCoIfB1liobg7JDhfWCL5YfifyKyE3DoK382o1KIeI+UgWJ+2LgQ3ffc0h5PIWP+Roiv5DyEnXMZtbezD4GPgIGZ0kSWesUeFub2Q1mtp7Il+zNsYjbzKoBw4H782irQNvazNoAv3H31/OJ9YhiDjQxsw+DwyydcqpQyM/1xRY5xDjNzH6TS50jjbsF4GY2zyKHXYflUKegn+sWQAsze9fMFptZfsmuIP+Ll6OkcMTqANuzTOc7ttIR1ito/fwUNO4jdUTtmtnJwCjguhxmJ1KImM3sj0R21cfkVudI23X3Je5+MtAOuDPzePEhCryt3f0f7t6UyJf43XkFfQTt3g885u4/5dFWIkcYs5lVAB4DbsszyuyijXkTcLy7twGGAv8ys5o51Cvotp4JNHb3U4A3+XUvPjfRthtP5HDuFcFzHzNLPaROIgWLOZ7IIaSzifyin2BmiTGIOVLZrD3ws7uvyqPNAinvSWE3kUMHmaIdWymsZ2bxQC3ghzyWs5Hshz0KO2ZTQeM+UlHHbWbHAa8CV7n7+hyq7KGAMZtZF+DPwIU57IEUOOZM7v4JsItIf8ihYrGt08h/Vz/auNsDo81sA3ArcJdFrvLPqiDbugaR9X8raPtMYEY+nZJRxezue9z9++D1MmA9kV/KhyrQtg4O62R+Lp4G2uYRc9RxB/X+7e7fBYcwZwOnH1KnoJ/rjcB0d9/n7l8QGc25eQxiztSXIthLAI6Kjuavgcr+ayfRF0Q6iJKC17VzeM8NZO9ofjHLvE9zWc5SIv9omZ1E5+cR0wDy72g+4riztDOJQzqaCxM3kV9LK4CLc2njLSK/8guyrdsQ+RJpnsO8wsTchF87mhsR+QerE6ttnTVe4AIgPZafkaD+feTe0Vzgz8eh6x+DbV2XoIMWOAH4JuvyY7Ct62d53QdYHKO4k4APCE5KILIX0iNGn+tuwLPB6zpBG8mx+HwQ+TG/kchhrTz/rgV5FPiNZeUBPAN0yTI9EPgseFydpfwBIr9UIfLL4KWgzn8zN37wx12Ty3JSgFVEvuDG8esQIhcCD2Spt4HIXsdPwR/2pJz+oAWMu13Q5i7ge+DjWMRN5NDILmB5lscxh8ZdwJjfBLZkaXdGjGK+kkhH7XIi//i9c/vnKWDcj2dpfxFwcqw+I1nq30fuSeGIY85j/Qu7rS8OtsWKYFtfEONt/VCW9hcBrWL4//jHoO1VwOhYbWsiX+yPAquJ9Gn1jWHMZ5MlMea2rQv6KPEv7aJ+EPkl+lyM2uoJ3FyEsWb95ylzcZfFmLWtta3L67Yu6KNUjZJaFNz9w+CijjjP+XSzI2kr2rM2jpiZLSKy670vWFaZi9vdV5S1mINlaVsXEW3r7IpzWxe4nSC7iIiIlPuzj0RE5AgoKYiISEhJQcoVM/spy+vzg0HLjjez+yzL4HK5vHdDMCDZR8FAZg9mDudhZg3MbFpRxy9S0pQUpFwKrkwdC3Rz96+O4K3nuHtr4AwinXbjAdz9W3ePauTZfOIq9yd3SNmmpCDlTjD2ztNELkTK6errfHlkmInBQG8zq22R4aFXBe0vCYb8yFzeW8Gwx9XM7J9mtjQYB6hXMH+Amb1kZjOBN8ysqpm9GIzlMzVoL3No6a4WGcr5g+A91YPyDWZ2f1D+kZm1Csqrm9nEoGylmV2cVzsi+VFSkPKmEpERLXu7+6eFacgjI6F+weHDE6QBl0E4umUDjwzv8Gdgobu3IzIk+JhggDuIDInc3907ExmaPcMjY/n8lWDYBjOrQ+RCwS7ufjqQTmQsoUzfBeVPApmHwv4C/OjurYP2FkbRjkiulBSkvNkHvEdkxNVYyGmgsheBS4PXlxG5+h0iQzHfYWbLiVxEVBk4Ppg3390zx8/qSCSx4JEBzVYG5WcCJwHvBm30JzJER6ZXgudlRO5hANAF+EdmBY8M1ZxfOyK50vFNKW8OEvmiftPM7nL3vxW0ITOrQeTLdy2RQREBcPdvzOx7MzuFyPDFmaPGGpHxodYc0k57IsOEkKVejoskkjz65TI/c1C4A/z6v2scPppmfu2I5Ep7ClLueGTEy57AFWZWoD2G4Bj8E8Brwa/vQ6UBw4Ba7v5RUDYPuMksckMmi9y/ICfv8Ovhp5OI3EELIjcZOsvMmgXzqppZTqONZvUGEI6iamZJBWxHBFBSkHIqOFTTDbg7s8M3eL0x85HLWxcFHcr/Bb4i53tHQOSOfH2JHErK9FegIrAyaOOvubz3CaCuma0kci+GlUT6BbYRGUF3SjBvMdAqn1V9EEgys1VmtoLI2VMFaUcE0DAXIsXOIjeAr+juv5hZU2AB0MLd95ZwaCLqUxApAVWJ7JFUJHL8/3olBCkttKcgIiIh9SmIiEhISUFEREJKCiIiElJSEBGRkJKCiIiE/j9SrEeCM9fb4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = []\n",
    "for i in (correctness2.index):\n",
    "    index.append(str(i))\n",
    "plt.bar(index,correctness2[\"percent\"], width=0.7)\n",
    "for index,data in enumerate(correctness2[\"percent\"]):\n",
    "    plt.text(x=index , y =data+1 , s=f\"{round(data,2)}\" , fontdict=dict(fontsize=15),ha='center')\n",
    "plt.ylim(0,110)\n",
    "plt.xlabel(\"KL Divergence\")\n",
    "plt.ylabel(\"% correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23f908a8288>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kl2 = table2[[\"correctness\",\"count\"]].groupby(pd.cut(table2[\"KL_div\"], np.arange(0, 0.8, 0.1))).apply(sum)\n",
    "kl2[\"percent\"] = (kl2[\"correctness\"]/kl2[\"count\"])\n",
    "kl2.dropna(inplace=True)\n",
    "plt.scatter(np.arange(0, 0.70, 0.1), kl2[\"percent\"])\n",
    "# print(kl)\n",
    "# print(np.arange(0, 0.7, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_reg2 = np.arange(0, 0.7, 0.1).reshape((-1, 1))\n",
    "y_reg2 = kl2[\"percent\"]\n",
    "reg_model2 = LinearRegression().fit(x_reg2,y_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept(alpha): 0.9778446925880102\n",
      "slope(theta): [-0.44327113]\n"
     ]
    }
   ],
   "source": [
    "print('intercept(alpha):', reg_model2.intercept_)\n",
    "print('slope(theta):', reg_model2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm C: It = argmax(Ct,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct answer\n",
    "ans = pd.DataFrame(X_df2[\"y_actual\"])\n",
    "\n",
    "# NN1\n",
    "alpha1 = reg_model1.intercept_\n",
    "theta1 = reg_model1.coef_\n",
    "\n",
    "# NN2\n",
    "alpha2 = reg_model2.intercept_\n",
    "theta2 = reg_model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             correctness  count   percent\n",
      "KL_div                                   \n",
      "(0.0, 0.05]        935.0  935.0  1.000000\n",
      "(0.05, 0.1]        229.0  233.0  0.982833\n",
      "(0.1, 0.15]        134.0  144.0  0.930556\n",
      "(0.15, 0.2]        109.0  116.0  0.939655\n",
      "(0.2, 0.25]         85.0   98.0  0.867347\n",
      "(0.25, 0.3]         54.0   63.0  0.857143\n",
      "(0.3, 0.35]         63.0   68.0  0.926471\n",
      "(0.35, 0.4]         38.0   49.0  0.775510\n",
      "(0.4, 0.45]         35.0   44.0  0.795455\n",
      "(0.45, 0.5]         32.0   50.0  0.640000\n",
      "(0.5, 0.55]         45.0   52.0  0.865385\n",
      "(0.55, 0.6]         30.0   35.0  0.857143\n",
      "(0.6, 0.65]         27.0   36.0  0.750000\n",
      "(0.65, 0.7]         50.0   77.0  0.649351\n",
      "(0.7, 0.75]          0.0    0.0       NaN\n"
     ]
    }
   ],
   "source": [
    "kl_div_table1 = table1[[\"correctness\",\"count\"]].groupby(pd.cut(table1[\"KL_div\"], np.arange(0, 0.8, 0.05))).apply(sum)\n",
    "kl_div_table1[\"percent\"] = (kl_div_table1[\"correctness\"]/kl_div_table1[\"count\"])\n",
    "\n",
    "kl_div_table2 = table2[[\"correctness\",\"count\"]].groupby(pd.cut(table2[\"KL_div\"], np.arange(0, 0.8, 0.05))).apply(sum)\n",
    "kl_div_table2[\"percent\"] = (kl_div_table2[\"correctness\"]/kl_div_table2[\"count\"])\n",
    "print(kl_div_table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KL_div</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>count</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.335157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.393614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.578759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.493294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.018534</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.669271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.041836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.076863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        KL_div  y_pred  count      conf\n",
       "0     0.098054     1.0      1  0.927439\n",
       "1     0.335157     1.0      1   0.75198\n",
       "2     0.393614     1.0      1  0.708722\n",
       "3     0.578759     1.0      1  0.571712\n",
       "4     0.172874     1.0      1  0.872072\n",
       "...        ...     ...    ...       ...\n",
       "1995  0.493294     1.0      1  0.634958\n",
       "1996  0.018534     1.0      1  0.986285\n",
       "1997  0.669271     0.0      1  0.504733\n",
       "1998  0.041836     0.0      1  0.969041\n",
       "1999  0.076863     1.0      1   0.94312\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating NN tables\n",
    "nn1 = table1.drop([\"abs_distance\",\"correctness\"], axis=1)\n",
    "nn1[\"conf\"] = 1 + theta1 * nn1[\"KL_div\"]\n",
    "\n",
    "# for i in range(0,len(nn1)):\n",
    "#     nn1.loc[i,\"conf\"] = kl_div_table1.loc[nn1.loc[i,\"KL_div\"],\"percent\"]\n",
    "\n",
    "nn2 = table2.drop([\"abs_distance\",\"correctness\"], axis=1)\n",
    "nn2[\"conf\"] = 1 + theta2 * nn2[\"KL_div\"]\n",
    "\n",
    "# for i in range(0,len(nn2)):\n",
    "#     nn2.loc[i,\"conf\"] = kl_div_table2.loc[nn2.loc[i,\"KL_div\"],\"percent\"]\n",
    "nn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_actual</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>chosen_NN</th>\n",
       "      <th>chosen_conf</th>\n",
       "      <th>not_NN</th>\n",
       "      <th>not_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.927439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.890384</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.751980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.768882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.857262</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.879662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.872072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.737147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.994425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.732730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.995237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.993075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_actual  y_pred  chosen_NN  chosen_conf  not_NN  not_conf\n",
       "0            1     1.0        2.0     0.999890     1.0  0.927439\n",
       "1            1     1.0        2.0     0.890384     1.0  0.751980\n",
       "2            1     1.0        2.0     0.768882     1.0  0.708722\n",
       "3            1     1.0        2.0     0.857262     1.0  0.571712\n",
       "4            1     1.0        2.0     0.879662     1.0  0.872072\n",
       "...        ...     ...        ...          ...     ...       ...\n",
       "1995         1     1.0        2.0     0.737147     1.0  0.634958\n",
       "1996         1     1.0        2.0     0.994425     1.0  0.986285\n",
       "1997         1     0.0        2.0     0.732730     1.0  0.504733\n",
       "1998         0     0.0        2.0     0.995237     1.0  0.969041\n",
       "1999         1     1.0        2.0     0.993075     1.0  0.943120\n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determing higher confidence NN and choosing that arm\n",
    "\n",
    "for i in range(0,len(nn1)):\n",
    "    if nn1.loc[i,\"conf\"] > nn2.loc[i,\"conf\"]:\n",
    "        ans.loc[i,\"y_pred\"] = nn1.loc[i,\"y_pred\"]\n",
    "        ans.loc[i,\"chosen_NN\"] = 1\n",
    "        ans.loc[i,\"chosen_conf\"] = nn1.loc[i,\"conf\"]\n",
    "\n",
    "        ans.loc[i,\"not_NN\"] = 2\n",
    "        ans.loc[i,\"not_conf\"] = nn2.loc[i,\"conf\"]\n",
    "    else:\n",
    "        ans.loc[i,\"y_pred\"] = nn2.loc[i,\"y_pred\"]\n",
    "        ans.loc[i,\"chosen_NN\"] = 2\n",
    "        ans.loc[i,\"chosen_conf\"] = nn2.loc[i,\"conf\"]\n",
    "\n",
    "        ans.loc[i,\"not_NN\"] = 1\n",
    "        ans.loc[i,\"not_conf\"] = nn1.loc[i,\"conf\"]\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_record = \"\"\n",
    "# NN1 performance\n",
    "cost1 = 0\n",
    "for i in range(0,len(nn1)):\n",
    "    if nn1.loc[i,\"y_pred\"] != ans.loc[i,\"y_actual\"]:\n",
    "        cost1 += 1 * nn1.loc[i,\"conf\"]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# NN2 performance\n",
    "cost2 = 0\n",
    "for i in range(0,len(nn2)):\n",
    "    if nn2.loc[i,\"y_pred\"] != ans.loc[i,\"y_actual\"]:\n",
    "        cost2 += 1 * nn2.loc[i,\"conf\"]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Combined performance\n",
    "cost3 = 0\n",
    "for i in range(0,len(nn1)):\n",
    "    chosen_nn = int(ans.loc[i,\"chosen_NN\"])\n",
    "    chosen_nn_conf = round(ans.loc[i,\"chosen_conf\"],3)\n",
    "    not_nn = int(ans.loc[i,\"not_NN\"])\n",
    "    not_nn_conf = round(ans.loc[i,\"not_conf\"],3)\n",
    "    if ans.loc[i,\"y_pred\"] != ans.loc[i,\"y_actual\"]:\n",
    "        cost3 += 1 * ans.loc[i,\"chosen_conf\"]\n",
    "        wrong_record = wrong_record + (f\"{i}: Wrong NN:{chosen_nn}, Conf:{chosen_nn_conf} - Other NN{not_nn}, Conf:{not_nn_conf} \") + \"\\n\"\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: Wrong NN:2, Conf:0.725 - Other NN1, Conf:0.56 \n",
      "23: Wrong NN:2, Conf:0.739 - Other NN1, Conf:0.644 \n",
      "31: Wrong NN:1, Conf:0.87 - Other NN2, Conf:0.852 \n",
      "68: Wrong NN:2, Conf:0.838 - Other NN1, Conf:0.77 \n",
      "96: Wrong NN:2, Conf:0.9 - Other NN1, Conf:0.615 \n",
      "118: Wrong NN:2, Conf:0.696 - Other NN1, Conf:0.603 \n",
      "129: Wrong NN:2, Conf:0.879 - Other NN1, Conf:0.666 \n",
      "133: Wrong NN:2, Conf:0.937 - Other NN1, Conf:0.656 \n",
      "146: Wrong NN:2, Conf:0.785 - Other NN1, Conf:0.686 \n",
      "153: Wrong NN:2, Conf:0.918 - Other NN1, Conf:0.672 \n",
      "179: Wrong NN:2, Conf:0.769 - Other NN1, Conf:0.487 \n",
      "186: Wrong NN:2, Conf:0.902 - Other NN1, Conf:0.7 \n",
      "190: Wrong NN:2, Conf:0.957 - Other NN1, Conf:0.606 \n",
      "209: Wrong NN:2, Conf:0.874 - Other NN1, Conf:0.621 \n",
      "247: Wrong NN:2, Conf:0.863 - Other NN1, Conf:0.62 \n",
      "251: Wrong NN:2, Conf:0.694 - Other NN1, Conf:0.488 \n",
      "271: Wrong NN:2, Conf:0.856 - Other NN1, Conf:0.555 \n",
      "306: Wrong NN:2, Conf:0.787 - Other NN1, Conf:0.731 \n",
      "312: Wrong NN:2, Conf:0.789 - Other NN1, Conf:0.626 \n",
      "325: Wrong NN:2, Conf:0.906 - Other NN1, Conf:0.543 \n",
      "342: Wrong NN:2, Conf:0.842 - Other NN1, Conf:0.488 \n",
      "373: Wrong NN:2, Conf:0.872 - Other NN1, Conf:0.598 \n",
      "398: Wrong NN:2, Conf:0.693 - Other NN1, Conf:0.604 \n",
      "416: Wrong NN:2, Conf:0.834 - Other NN1, Conf:0.721 \n",
      "449: Wrong NN:2, Conf:0.959 - Other NN1, Conf:0.494 \n",
      "462: Wrong NN:2, Conf:0.823 - Other NN1, Conf:0.667 \n",
      "487: Wrong NN:2, Conf:0.84 - Other NN1, Conf:0.674 \n",
      "491: Wrong NN:2, Conf:0.854 - Other NN1, Conf:0.763 \n",
      "510: Wrong NN:2, Conf:0.711 - Other NN1, Conf:0.492 \n",
      "511: Wrong NN:2, Conf:0.816 - Other NN1, Conf:0.718 \n",
      "521: Wrong NN:2, Conf:0.696 - Other NN1, Conf:0.494 \n",
      "540: Wrong NN:1, Conf:0.801 - Other NN2, Conf:0.698 \n",
      "557: Wrong NN:2, Conf:0.867 - Other NN1, Conf:0.712 \n",
      "578: Wrong NN:2, Conf:0.796 - Other NN1, Conf:0.77 \n",
      "579: Wrong NN:2, Conf:0.954 - Other NN1, Conf:0.487 \n",
      "606: Wrong NN:2, Conf:0.788 - Other NN1, Conf:0.507 \n",
      "624: Wrong NN:2, Conf:0.886 - Other NN1, Conf:0.636 \n",
      "637: Wrong NN:2, Conf:0.719 - Other NN1, Conf:0.711 \n",
      "655: Wrong NN:2, Conf:0.821 - Other NN1, Conf:0.611 \n",
      "763: Wrong NN:2, Conf:0.832 - Other NN1, Conf:0.708 \n",
      "776: Wrong NN:2, Conf:0.789 - Other NN1, Conf:0.667 \n",
      "796: Wrong NN:2, Conf:0.894 - Other NN1, Conf:0.777 \n",
      "838: Wrong NN:2, Conf:0.906 - Other NN1, Conf:0.869 \n",
      "868: Wrong NN:2, Conf:0.778 - Other NN1, Conf:0.756 \n",
      "929: Wrong NN:2, Conf:0.911 - Other NN1, Conf:0.541 \n",
      "939: Wrong NN:2, Conf:0.765 - Other NN1, Conf:0.701 \n",
      "965: Wrong NN:2, Conf:0.836 - Other NN1, Conf:0.754 \n",
      "970: Wrong NN:2, Conf:0.749 - Other NN1, Conf:0.537 \n",
      "971: Wrong NN:2, Conf:0.868 - Other NN1, Conf:0.654 \n",
      "976: Wrong NN:2, Conf:0.796 - Other NN1, Conf:0.495 \n",
      "993: Wrong NN:2, Conf:0.789 - Other NN1, Conf:0.703 \n",
      "995: Wrong NN:2, Conf:0.79 - Other NN1, Conf:0.749 \n",
      "998: Wrong NN:2, Conf:0.8 - Other NN1, Conf:0.757 \n",
      "1029: Wrong NN:2, Conf:0.908 - Other NN1, Conf:0.611 \n",
      "1048: Wrong NN:2, Conf:0.909 - Other NN1, Conf:0.645 \n",
      "1077: Wrong NN:2, Conf:0.696 - Other NN1, Conf:0.54 \n",
      "1085: Wrong NN:2, Conf:0.824 - Other NN1, Conf:0.51 \n",
      "1090: Wrong NN:2, Conf:0.945 - Other NN1, Conf:0.724 \n",
      "1120: Wrong NN:1, Conf:0.851 - Other NN2, Conf:0.832 \n",
      "1124: Wrong NN:2, Conf:0.946 - Other NN1, Conf:0.606 \n",
      "1125: Wrong NN:2, Conf:0.841 - Other NN1, Conf:0.77 \n",
      "1195: Wrong NN:2, Conf:0.956 - Other NN1, Conf:0.489 \n",
      "1197: Wrong NN:2, Conf:0.774 - Other NN1, Conf:0.524 \n",
      "1260: Wrong NN:2, Conf:0.877 - Other NN1, Conf:0.488 \n",
      "1270: Wrong NN:2, Conf:0.949 - Other NN1, Conf:0.487 \n",
      "1274: Wrong NN:2, Conf:0.802 - Other NN1, Conf:0.489 \n",
      "1281: Wrong NN:2, Conf:0.697 - Other NN1, Conf:0.493 \n",
      "1288: Wrong NN:2, Conf:0.921 - Other NN1, Conf:0.665 \n",
      "1293: Wrong NN:2, Conf:0.802 - Other NN1, Conf:0.787 \n",
      "1304: Wrong NN:2, Conf:0.921 - Other NN1, Conf:0.653 \n",
      "1328: Wrong NN:2, Conf:0.838 - Other NN1, Conf:0.752 \n",
      "1337: Wrong NN:2, Conf:0.705 - Other NN1, Conf:0.576 \n",
      "1340: Wrong NN:2, Conf:0.956 - Other NN1, Conf:0.494 \n",
      "1355: Wrong NN:2, Conf:0.709 - Other NN1, Conf:0.553 \n",
      "1356: Wrong NN:2, Conf:0.805 - Other NN1, Conf:0.754 \n",
      "1392: Wrong NN:2, Conf:0.891 - Other NN1, Conf:0.685 \n",
      "1397: Wrong NN:2, Conf:0.799 - Other NN1, Conf:0.769 \n",
      "1446: Wrong NN:2, Conf:0.805 - Other NN1, Conf:0.511 \n",
      "1483: Wrong NN:2, Conf:0.856 - Other NN1, Conf:0.82 \n",
      "1500: Wrong NN:2, Conf:0.961 - Other NN1, Conf:0.489 \n",
      "1551: Wrong NN:2, Conf:0.869 - Other NN1, Conf:0.74 \n",
      "1552: Wrong NN:2, Conf:0.801 - Other NN1, Conf:0.739 \n",
      "1589: Wrong NN:2, Conf:0.938 - Other NN1, Conf:0.507 \n",
      "1654: Wrong NN:1, Conf:0.816 - Other NN2, Conf:0.732 \n",
      "1679: Wrong NN:2, Conf:0.697 - Other NN1, Conf:0.637 \n",
      "1693: Wrong NN:2, Conf:0.694 - Other NN1, Conf:0.583 \n",
      "1705: Wrong NN:2, Conf:0.927 - Other NN1, Conf:0.74 \n",
      "1714: Wrong NN:2, Conf:0.944 - Other NN1, Conf:0.695 \n",
      "1720: Wrong NN:2, Conf:0.928 - Other NN1, Conf:0.548 \n",
      "1738: Wrong NN:2, Conf:0.78 - Other NN1, Conf:0.631 \n",
      "1742: Wrong NN:2, Conf:0.909 - Other NN1, Conf:0.539 \n",
      "1753: Wrong NN:2, Conf:0.907 - Other NN1, Conf:0.601 \n",
      "1760: Wrong NN:2, Conf:0.91 - Other NN1, Conf:0.791 \n",
      "1764: Wrong NN:2, Conf:0.697 - Other NN1, Conf:0.585 \n",
      "1786: Wrong NN:2, Conf:0.774 - Other NN1, Conf:0.541 \n",
      "1842: Wrong NN:2, Conf:0.938 - Other NN1, Conf:0.667 \n",
      "1845: Wrong NN:2, Conf:0.917 - Other NN1, Conf:0.647 \n",
      "1851: Wrong NN:2, Conf:0.941 - Other NN1, Conf:0.493 \n",
      "1858: Wrong NN:2, Conf:0.885 - Other NN1, Conf:0.779 \n",
      "1872: Wrong NN:2, Conf:0.803 - Other NN1, Conf:0.724 \n",
      "1902: Wrong NN:2, Conf:0.918 - Other NN1, Conf:0.663 \n",
      "1913: Wrong NN:2, Conf:0.891 - Other NN1, Conf:0.849 \n",
      "1928: Wrong NN:2, Conf:0.789 - Other NN1, Conf:0.49 \n",
      "1956: Wrong NN:2, Conf:0.843 - Other NN1, Conf:0.744 \n",
      "1997: Wrong NN:2, Conf:0.733 - Other NN1, Conf:0.505 \n",
      "\n",
      "Error count for NN1:66.9460297847183, NN2:108.83716989761089, Combined:87.94946224971173\n"
     ]
    }
   ],
   "source": [
    "print(wrong_record)\n",
    "print(f\"Error count for NN1:{cost1}, NN2:{cost2}, Combined:{cost3}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
